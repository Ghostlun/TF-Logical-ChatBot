{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved LLM Plans\n",
    "Original feature, Only one mental Keggle Mental health information used.\n",
    "Then, based on information, how should I imporve my model,\n",
    "In inital Training, gpt model4, and we have serveral information inside.\n",
    "Next approch, I like to Hugging Datasets and Mental health datasets\n",
    "\n",
    "Currently, feature we just populate randomly.\n",
    "Next what, I want is text related llm topic clustering,\n",
    "Based on token, clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Datasets called\n",
    "raw_data_path = \"raw_data\"\n",
    "cleaned_data_path= \"cleaned_data\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1373, 4)\n",
      "(2775, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ykim\\AppData\\Local\\Temp\\ipykernel_28620\\3358003086.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
      "C:\\Users\\ykim\\AppData\\Local\\Temp\\ipykernel_28620\\3358003086.py:19: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questionText</th>\n",
       "      <th>topic</th>\n",
       "      <th>answerText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do i have too many issues for counseling i hav...</td>\n",
       "      <td>depression</td>\n",
       "      <td>it is very common for people to have multiple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do i have too many issues for counseling i hav...</td>\n",
       "      <td>depression</td>\n",
       "      <td>ive never heard of someone having too many iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do i have too many issues for counseling i hav...</td>\n",
       "      <td>depression</td>\n",
       "      <td>absolutely not  i strongly recommending workin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>do i have too many issues for counseling i hav...</td>\n",
       "      <td>depression</td>\n",
       "      <td>let me start by saying there are never too man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do i have too many issues for counseling i hav...</td>\n",
       "      <td>depression</td>\n",
       "      <td>i just want to acknowledge you for the courage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2770</th>\n",
       "      <td>are some clients more difficult than others wh...</td>\n",
       "      <td>counselingfundamentals</td>\n",
       "      <td>although many clients have the capacity to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>are some clients more difficult than others wh...</td>\n",
       "      <td>counselingfundamentals</td>\n",
       "      <td>i usually dont label a client as difficult bec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>are some clients more difficult than others wh...</td>\n",
       "      <td>counselingfundamentals</td>\n",
       "      <td>dang right  heh heh and correct me if im wrong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>are some clients more difficult than others wh...</td>\n",
       "      <td>counselingfundamentals</td>\n",
       "      <td>yes just like some relationships outside of ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>are some clients more difficult than others wh...</td>\n",
       "      <td>counselingfundamentals</td>\n",
       "      <td>each counselor will have their own list of dif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2775 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questionText  \\\n",
       "0     do i have too many issues for counseling i hav...   \n",
       "1     do i have too many issues for counseling i hav...   \n",
       "2     do i have too many issues for counseling i hav...   \n",
       "3     do i have too many issues for counseling i hav...   \n",
       "4     do i have too many issues for counseling i hav...   \n",
       "...                                                 ...   \n",
       "2770  are some clients more difficult than others wh...   \n",
       "2771  are some clients more difficult than others wh...   \n",
       "2772  are some clients more difficult than others wh...   \n",
       "2773  are some clients more difficult than others wh...   \n",
       "2774  are some clients more difficult than others wh...   \n",
       "\n",
       "                       topic  \\\n",
       "0                 depression   \n",
       "1                 depression   \n",
       "2                 depression   \n",
       "3                 depression   \n",
       "4                 depression   \n",
       "...                      ...   \n",
       "2770  counselingfundamentals   \n",
       "2771  counselingfundamentals   \n",
       "2772  counselingfundamentals   \n",
       "2773  counselingfundamentals   \n",
       "2774  counselingfundamentals   \n",
       "\n",
       "                                             answerText  \n",
       "0     it is very common for people to have multiple ...  \n",
       "1     ive never heard of someone having too many iss...  \n",
       "2     absolutely not  i strongly recommending workin...  \n",
       "3     let me start by saying there are never too man...  \n",
       "4     i just want to acknowledge you for the courage...  \n",
       "...                                                 ...  \n",
       "2770  although many clients have the capacity to be ...  \n",
       "2771  i usually dont label a client as difficult bec...  \n",
       "2772  dang right  heh heh and correct me if im wrong...  \n",
       "2773  yes just like some relationships outside of ou...  \n",
       "2774  each counselor will have their own list of dif...  \n",
       "\n",
       "[2775 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Inital Raw Data Used.\n",
    "\n",
    "def clean_keggle_df(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df[[\"questionText\", \"topics\", \"re_diagnosis\",\"clean_answer_text\"]]\n",
    "    # Lower case\n",
    "    df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    # remove non-world\n",
    "    df = df.replace(to_replace=r'[^\\w\\s]', value=\"\", regex=True)\n",
    "    # remove number\n",
    "    df = df.replace(to_replace=r'\\d', value='', regex=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_hugging_df(data_path):\n",
    "    df = pd.read_csv(data_path)\n",
    "    df = df[[\"questionTitle\", \"questionText\", \"topic\", \"answerText\"]]\n",
    "    df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    df[\"questionText\"] = df[\"questionTitle\"].fillna('') + \" \" + df[\"questionText\"].fillna('')\n",
    "    df = df.replace(to_replace=r'[^\\w\\s]', value=\"\", regex=True)\n",
    "    df = df.replace(to_replace=r'\\d', value='', regex=True)\n",
    "    df = df[[\"questionText\", \"topic\", \"answerText\"]]\n",
    "    return df\n",
    "\n",
    "keggle_df = clean_keggle_df(f\"{raw_data_path}/counsel_cleaned.csv\")   \n",
    "print(keggle_df.shape)\n",
    "keggle_df.to_csv(f\"{cleaned_data_path}/cleaned_counsel.csv\")\n",
    "hugging_df = clean_hugging_df(f\"{raw_data_path}/huggin_counsel_chat.csv\")\n",
    "print(hugging_df.shape)\n",
    "hugging_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After renaming: Index(['questionTitle', 'question_text', 'topics', 'answer_text'], dtype='object')\n",
      "Index(['questionText', 'topics', 'clean_answer_text'], dtype='object')\n",
      "Index(['question_text', 'topics', 'answer_text'], dtype='object')\n",
      "Index(['question_text', 'topics', 'answer_text'], dtype='object')\n",
      "Index(['question_text', 'topics', 'answer_text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read File Information\n",
    "hugging_df = pd.read_csv(f\"{cleaned_data_path}/cleaned_hugging.csv\")\n",
    "counsel_df = pd.read_csv(f\"{cleaned_data_path}/cleaned_counsel.csv\")\n",
    "\n",
    "# Change Column Name\n",
    "hugging_df.rename(columns={\"questionText\": \"question_text\",\n",
    "                           \"topic\": \"topics\", \n",
    "                           \"answerText\": \"answer_text\"}, inplace=True)\n",
    "hugging_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "print(\"After renaming:\", hugging_df.columns)\n",
    "# Drop unused column\n",
    "counsel_df.drop(columns=['Unnamed: 0', 're_diagnosis'], inplace=True)\n",
    "print(counsel_df.columns)\n",
    "counsel_df.rename(columns={\"questionText\": \"question_text\", \n",
    "                           \"clean_answer_text\": \"answer_text\"}, inplace=True)\n",
    "\n",
    "# Select target column\n",
    "hugging_df = hugging_df[[\"question_text\", \"topics\", \"answer_text\"]]\n",
    "counsel_df = counsel_df[[\"question_text\", \"topics\", \"answer_text\"]]\n",
    "\n",
    "# Concat Column\n",
    "combined_dataset = pd.concat([hugging_df, counsel_df], ignore_index=True)\n",
    "\n",
    "# Combined Output\n",
    "combined_dataset.to_csv(f\"{cleaned_data_path}/combined_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'question_text', 'topics', 'answer_text'], dtype='object')\n",
      "<bound method NDFrame.head of       Unnamed: 0                                      question_text  \\\n",
      "0              0  i have so many issues to address i have a hist...   \n",
      "1              1  i have so many issues to address i have a hist...   \n",
      "2              2  i have so many issues to address i have a hist...   \n",
      "3              3  i have so many issues to address i have a hist...   \n",
      "4              4  i have so many issues to address i have a hist...   \n",
      "...          ...                                                ...   \n",
      "4143        4143  my grandsons stepmother sends him to school wi...   \n",
      "4144        4144  my boyfriend is in recovery from drug addictio...   \n",
      "4145        4145  the birth mother attempted suicide several tim...   \n",
      "4146        4146  i think adult life is making him depressed and...   \n",
      "4147        4147  i just took a job that requires me to travel f...   \n",
      "\n",
      "                                             topics  \\\n",
      "0                                        depression   \n",
      "1                                        depression   \n",
      "2                                        depression   \n",
      "3                                        depression   \n",
      "4                                        depression   \n",
      "...                                             ...   \n",
      "4143                       parentingfamily conflict   \n",
      "4144                         relationshipsaddiction   \n",
      "4145  family conflictparentingchildren  adolescents   \n",
      "4146         relationshipsdepressionsubstance abuse   \n",
      "4147                       anxietycareer counseling   \n",
      "\n",
      "                                            answer_text  \n",
      "0     it is very common for people to have multiple ...  \n",
      "1     ive never heard of someone having too many iss...  \n",
      "2     absolutely not  i strongly recommending workin...  \n",
      "3     let me start by saying there are never too man...  \n",
      "4     i just want to acknowledge you for the courage...  \n",
      "...                                                 ...  \n",
      "4143  absolutely not it is never in a childs best in...  \n",
      "4144  im sorry you have tension between you and your...  \n",
      "4145  the true answer is no one can really say with ...  \n",
      "4146  how do you help yourself to believe you requir...  \n",
      "4147                            hmm this is a tough one  \n",
      "\n",
      "[4148 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Chat Promt, Design.\n",
    "combined_dataset = pd.read_csv(f\"{cleaned_data_path}/combined_output.csv\")\n",
    "print(combined_dataset.columns)\n",
    "print(combined_dataset.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This is an example.', 'Here is another sentence.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\ykim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK test\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "text = \"This is an example. Here is another sentence.\"\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (4148, 4)\n",
      "After: (3985, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ykim\\AppData\\Local\\Temp\\ipykernel_28620\\1488087169.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['q_token_count'] = df['question_text'].apply(token_count)\n",
      "C:\\Users\\ykim\\AppData\\Local\\Temp\\ipykernel_28620\\1488087169.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['a_token_count'] = df['answer_text'].apply(token_count)\n"
     ]
    }
   ],
   "source": [
    "# Cleaned Combined Datasets too shorts and too long\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def is_noisy(text: str) -> bool:\n",
    "    if re.search(r'[가-힣A-Za-z]', text) is None:\n",
    "        return True\n",
    "    cleaned = re.sub(r'[^\\w\\s]', '', text) \n",
    "    if len(cleaned) == 0 or len(cleaned) < len(text) * 0.02:  \n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clean_combined_dataset(df):\n",
    "    def token_count(text):\n",
    "        tokens = sent_tokenize(text)\n",
    "        return len(tokens)\n",
    "    # Apply the token_count function to calculate the number of tokens in questions and answers\n",
    "    df = df.dropna()\n",
    "    df['q_token_count'] = df['question_text'].apply(token_count)\n",
    "    df['a_token_count'] = df['answer_text'].apply(token_count)\n",
    "    \n",
    "    return df\n",
    "# print(combined_dataset.columns)\n",
    "print(f\"Before: {combined_dataset.shape}\")\n",
    "cleaned_combined_df = clean_combined_dataset(combined_dataset)\n",
    "cleaned_combined_df.to_csv(f\"{cleaned_data_path}/cleaned_combined.csv\")\n",
    "print(f\"After: {cleaned_combined_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    3985.000000\n",
      "mean      975.754580\n",
      "std       672.451943\n",
      "min         9.000000\n",
      "25%       508.000000\n",
      "50%       802.000000\n",
      "75%      1236.000000\n",
      "max      5380.000000\n",
      "Name: a_text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"cleaned_data/cleaned_combined.csv\", encoding=\"utf-8\")\n",
    "df = df.drop(columns=[col for col in df.columns if 'Unnamed' in col])\n",
    "\n",
    "df['a_text_length'] = df['answer_text'].astype(str).apply(len)\n",
    "\n",
    "print(df['a_text_length'].describe())\n",
    "MAX_LENGTH_COUNT =  1200\n",
    "MIN_LENGTH_COUNT =  200\n",
    "\n",
    "filter_df = df[(df['a_text_length'] <= MAX_LENGTH_COUNT) &\n",
    "               (df['a_text_length'] >= MIN_LENGTH_COUNT)] .copy()\n",
    "filter_df.to_csv(\"cleaned_data/filtered.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Filter Drop parts\n",
    "df = pd.read_csv(\"cleaned_data/filtered.csv\", encoding=\"utf-8\")\n",
    "df = df.drop(columns=[col for col in df.columns if 'Unnamed' in col])\n",
    "\n",
    "df_unique_questions = df.drop_duplicates(subset='question_text')\n",
    "df_unique_questions.to_csv(\"cleaned_data/03_unique_data.csv\")\n",
    "\n",
    "# Re_Sample_information\n",
    "df_sampled = df_unique_questions.sample(n=300, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ykim\\Desktop\\Personal\\Mental-Health-AI-Driven-System-Project\\.venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "100%|██████████| 300/300 [04:17<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Zero-shot classification pipeline \n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Improved T/F Classfication\n",
    "def classify_tf_zero_shot(text):\n",
    "    labels = [\n",
    "        \"This response contains logical reasoning.\",\n",
    "        \"This response provides emotional support.\"\n",
    "    ]\n",
    "    try:\n",
    "        result = classifier(\n",
    "            text,\n",
    "            candidate_labels=labels,\n",
    "            hypothesis_template=\"{}\"\n",
    "        )\n",
    "        top_label = result['labels'][0]\n",
    "        score = result['scores'][0]\n",
    "        # T/F mapping\n",
    "        if \"logical reasoning\" in top_label:\n",
    "            tf_type = \"T\"\n",
    "        elif \"emotional support\" in top_label:\n",
    "            tf_type = \"F\"\n",
    "        else:\n",
    "            tf_type = \"Unknown\"\n",
    "        return pd.Series([tf_type, score])\n",
    "    except Exception as e:\n",
    "        return pd.Series([None, None])  # 오류 발생 시\n",
    "\n",
    "# Handle Data frame\n",
    "tqdm.pandas()\n",
    "df_sampled[['tf_type_zero_shot', 'tf_score']] = df_sampled['answer_text'].progress_apply(classify_tf_zero_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 9)\n",
      "(98, 9)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Point for\n",
    "# df_sampled.to_csv(\"cleaned_data/accurate_sample.csv\")\n",
    "df_sampled = pd.read_csv(\"cleaned_data/accurate_sample.csv\")\n",
    "\n",
    "df_sampled_F = df_sampled[df_sampled['tf_type_zero_shot'] == \"F\"]\n",
    "df_sampled_F.to_csv(\"cleaned_data/accurate_F_sample.csv\")\n",
    "print(df_sampled_F.shape)\n",
    "df_sampled_T = df_sampled[df_sampled['tf_type_zero_shot'] == \"T\"]\n",
    "df_sampled_T.to_csv(\"cleaned_data/accurate_T_sample.csv\")\n",
    "print(df_sampled_T.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import pandas as pd\n",
    "\n",
    "# Create a working copy\n",
    "df_labeled = df_sampled.copy()\n",
    "\n",
    "# Select 'F' samples with low confidence (likely mislabeled)\n",
    "df_pseudo_T = df_labeled[\n",
    "    (df_labeled['tf_type_zero_shot'] == \"F\") &\n",
    "    (df_labeled['tf_score'] < 0.55) &\n",
    "    (df_labeled['tf_score'] > 0.30)\n",
    "].copy()\n",
    "\n",
    "# Force-label these as 'T'\n",
    "df_pseudo_T['tf_type_zero_shot'] = \"T\"\n",
    "\n",
    "# Combine original T + pseudo-labeled T\n",
    "df_minority_extended = pd.concat([\n",
    "    df_labeled[df_labeled['tf_type_zero_shot'] == \"T\"],\n",
    "    df_pseudo_T\n",
    "])\n",
    "\n",
    "# Resample T up to match F count\n",
    "df_majority = df_labeled[df_labeled['tf_type_zero_shot'] == \"F\"]\n",
    "df_minority_upsampled = resample(\n",
    "    df_minority_extended,\n",
    "    replace=True,\n",
    "    n_samples=len(df_majority),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine into a balanced dataset\n",
    "df_balanced = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.79      0.80      0.80        41\n",
      "           T       0.79      0.78      0.78        40\n",
      "\n",
      "    accuracy                           0.79        81\n",
      "   macro avg       0.79      0.79      0.79        81\n",
      "weighted avg       0.79      0.79      0.79        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train/Test Split\n",
    "\n",
    "df_labeled = df_balanced[['answer_text', 'tf_type_zero_shot']]\n",
    "\n",
    "# Split into training and validation sets (stratified)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    df_labeled['answer_text'],\n",
    "    df_labeled['tf_type_zero_shot'],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_labeled['tf_type_zero_shot']\n",
    ")\n",
    "\n",
    "# Feature Extraction (TF-IDF)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Use bi-grams and limit to 5000 features\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "\n",
    "# Fit on training, transform both train and validation\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_val_vec = vectorizer.transform(X_val)\n",
    "\n",
    "\n",
    "# Classifier Training (Logistic Regression)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train logistic regression model\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train_vec, y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = clf.predict(X_val_vec)\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Predict on full dataset with probabilities\n",
    "proba = clf.predict_proba(vectorizer.transform(df['answer_text']))\n",
    "df['predicted_tf_type'] = clf.predict(vectorizer.transform(df['answer_text']))\n",
    "df['proba_F'] = proba[:, 0]\n",
    "df['proba_T'] = proba[:, 1]\n",
    "\n",
    "df.to_csv(\"cleaned_data/prob_all.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After deduplication: (2149, 10)\n",
      "df_T_confident (300, 10)\n",
      "df_F_confident (300, 10)\n"
     ]
    }
   ],
   "source": [
    "# Load Predictions and Deduplicate\n",
    "df = pd.read_csv(\"cleaned_data/prob_all.csv\")\n",
    "df = df.drop_duplicates(subset=['answer_text', 'question_text'])\n",
    "print(\"After deduplication:\", df.shape)\n",
    "\n",
    "# Filtered by class\n",
    "df_T_confident = df[df['predicted_tf_type'] == 'T'].sort_values(by='proba_T', ascending=False).head(300)\n",
    "print(\"df_T_confident\", df_T_confident.shape)\n",
    "df_F_confident = df[df['predicted_tf_type'] == 'F'].sort_values(by='proba_F', ascending=False).head(300)\n",
    "print(\"df_F_confident\", df_F_confident.shape)\n",
    "\n",
    "\n",
    "df_balanced_concat = pd.concat([df_T_confident, df_F_confident]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.count of      Unnamed: 0.3  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
      "0               0             0             0        2535   \n",
      "1               1             1             1         668   \n",
      "2               2             2             2        1153   \n",
      "3               3             3             3        1638   \n",
      "4               4             4             4         371   \n",
      "..            ...           ...           ...         ...   \n",
      "595           595           595           595        1260   \n",
      "596           596           596           596         260   \n",
      "597           597           597           597         529   \n",
      "598           598           598           598         132   \n",
      "599           599           599           599        1918   \n",
      "\n",
      "                                         question_text  \\\n",
      "0    she refuses to talk to me and told my mom her ...   \n",
      "1    she refuses to talk to me and told my mom her ...   \n",
      "2    i have no idea what happened i go places and d...   \n",
      "3    im having a quinceañera and the girls dont lik...   \n",
      "4    i am a really shy person im currently in a gra...   \n",
      "..                                                 ...   \n",
      "595  it was over  years ago but the pain has resurf...   \n",
      "596  i feel like i am internally screaming all the ...   \n",
      "597  my toddler defies everything i say and doesnt ...   \n",
      "598  im going through some things with my feelings ...   \n",
      "599  cheating is something unacceptable for me but ...   \n",
      "\n",
      "                       topics  \\\n",
      "0    family conflictparenting   \n",
      "1                   parenting   \n",
      "2                    intimacy   \n",
      "3         socialrelationships   \n",
      "4                     anxiety   \n",
      "..                        ...   \n",
      "595            familyconflict   \n",
      "596                depression   \n",
      "597                   anxiety   \n",
      "598                depression   \n",
      "599     relationshipsmarriage   \n",
      "\n",
      "                                           answer_text  q_token_count  \\\n",
      "0    sorry to hear about your high degree of stress...              1   \n",
      "1    sorry to hear about your high degree of stress...              1   \n",
      "2    a lot of times any and each of us creates what...              1   \n",
      "3    how did you find out that the girls arent happ...              1   \n",
      "4    i wanted to share these two short books see be...              1   \n",
      "..                                                 ...            ...   \n",
      "595  affairs and infidelity are tough areas to addr...              1   \n",
      "596  as far as the formal diagnosis of depression g...              1   \n",
      "597  thats a good question i would say learn to pic...              1   \n",
      "598  i know feeling worthless is very hard to handl...              1   \n",
      "599  lets just start with acknowledging that trust ...              1   \n",
      "\n",
      "     a_token_count  a_text_length predicted_tf_type   proba_F   proba_T  \n",
      "0                1            758                 T  0.204026  0.795974  \n",
      "1                1            758                 T  0.204026  0.795974  \n",
      "2                1            845                 T  0.227665  0.772335  \n",
      "3                1            811                 T  0.229266  0.770734  \n",
      "4                1            217                 T  0.242734  0.757266  \n",
      "..             ...            ...               ...       ...       ...  \n",
      "595              1            985                 F  0.698181  0.301819  \n",
      "596              1            848                 F  0.698133  0.301867  \n",
      "597              1            780                 F  0.697951  0.302049  \n",
      "598              1            877                 F  0.697792  0.302208  \n",
      "599              1            542                 F  0.697447  0.302553  \n",
      "\n",
      "[600 rows x 13 columns]>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "df_balanced_concat.to_csv(\"cleaned_data/04_final_600.csv\")\n",
    "df_balanced_concat = pd.read_csv(\"cleaned_data/04_final_600.csv\")\n",
    "print(df_balanced_concat.count)\n",
    "\n",
    "def get_system_prompt(tf_type):\n",
    "    if tf_type == \"T\":\n",
    "        return \"You are a mental health assistant. Respond either with logical reasoning or emotional support depending on the user’s needs.\"\n",
    "    else:\n",
    "        return \"You are a mental health assistant. Use emotional support and validation in your response.\"\n",
    "\n",
    "jsonl_data = []\n",
    "\n",
    "for _, row in df_balanced_concat.iterrows():\n",
    "    system_msg = get_system_prompt(row['predicted_tf_type'])\n",
    "    user_msg = row['question_text'].strip()\n",
    "    assistant_msg = row['answer_text'].strip()\n",
    "\n",
    "    entry = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\", \"content\": user_msg},\n",
    "            {\"role\": \"assistant\", \"content\": assistant_msg}\n",
    "        ]\n",
    "    }\n",
    "    jsonl_data.append(entry)\n",
    "\n",
    "# Save\n",
    "\n",
    "with open(\"600_Chat_Turning.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for entry in jsonl_data:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
